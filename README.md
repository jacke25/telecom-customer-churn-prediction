# ğŸ“Š Customer Churn Prediction â€” Machine Learning Project

Este proyecto implementa un modelo de **Machine Learning** para predecir el abandono de clientes (*churn*) en una empresa de telecomunicaciones. Se desarrolla un pipeline completo, desde el anÃ¡lisis exploratorio hasta la evaluaciÃ³n final del modelo, incorporando buenas prÃ¡cticas profesionales como validaciÃ³n cruzada, pruebas de cordura y optimizaciÃ³n del threshold.

El objetivo principal del proyecto fue superar un **AUC-ROC â‰¥ 0.88** en el conjunto de prueba.  
El modelo final alcanzÃ³ un **AUC-ROC de 0.903**.

---

## ğŸš€ 1. Objetivo del Proyecto

Interconnect, un operador de telecomunicaciones, busca identificar clientes en riesgo de abandonar el servicio para ofrecerles planes de retenciÃ³n personalizados. El objetivo del proyecto es:

- Construir un modelo predictivo de churn estable y explicable.
- Evaluar distintos algoritmos de ML.
- Optimizar su capacidad para detectar clientes en riesgo (Recall).
- Cumplir con la mÃ©trica objetivo: **AUC-ROC â‰¥ 0.88**.

---

## ğŸ“ 2. Contenido del Repositorio

- `customer_churn_prediction.ipynb` â†’ Notebook completo con el pipeline end-to-end.  
- `data/` â†’ Estructura esperada de los archivos (o instrucciones para obtenerlos).  
- `README.md` â†’ DocumentaciÃ³n del proyecto.  

---

## ğŸ§  3. Dataset

El proyecto utiliza cuatro fuentes:

- `contract.csv` â†’ InformaciÃ³n contractual  
- `personal.csv` â†’ Datos demogrÃ¡ficos  
- `internet.csv` â†’ Servicios de internet  
- `phone.csv` â†’ Servicios telefÃ³nicos  

Cada archivo contiene la columna **customerID**, usada como clave para unir los datasets.

---

## ğŸ” 4. MetodologÃ­a

El pipeline completo incluye:

### âœ”ï¸ ExploraciÃ³n de Datos (EDA)
- AnÃ¡lisis univariado y bivariado.
- RelaciÃ³n entre churn y variables demogrÃ¡ficas, contractuales y de servicios.
- IdentificaciÃ³n de caracterÃ­sticas con mayor correlaciÃ³n con abandono.

### âœ”ï¸ PreparaciÃ³n de Datos
- Limpieza de valores nulos (`TotalCharges` conversion).
- ConversiÃ³n de tipos de datos.
- UnificaciÃ³n de tablas.
- CodificaciÃ³n categÃ³rica:
  - OHE para modelos lineales
  - Manejo nativo para CatBoost / LightGBM
- DivisiÃ³n en **Train / Validation / Test**.

### âœ”ï¸ Modelado
Modelos evaluados:

| Modelo | AUC Validation |
|--------|----------------|
| **CatBoost** | **0.922** |
| LightGBM | 0.912 |
| Random Forest | 0.878 |
| Logistic Regression | 0.873 |
| Decision Tree | 0.869 |

CatBoost fue seleccionado como modelo final.

### âœ”ï¸ Pruebas de Cordura
- **DummyClassifier** â†’ AUC â‰ˆ 0.50  
- **Etiquetas aleatorias** â†’ AUC â‰ˆ 0.51  

Ambas pruebas confirman ausencia de *data leakage*.

### âœ”ï¸ ValidaciÃ³n Cruzada
- CV AUC: **0.9078**

### âœ”ï¸ OptimizaciÃ³n de HiperparÃ¡metros
Se utilizÃ³ **RandomizedSearchCV** para optimizar:
- `depth`  
- `learning_rate`  
- `iterations`  
- `l2_leaf_reg`  
- `border_count`  

### âœ”ï¸ OptimizaciÃ³n del Threshold
Se evaluaron 50 thresholds entre 0.1 y 0.9 para maximizar Recall y F1.

---

## ğŸ“ˆ 5. Resultados del Modelo Final

Tras entrenar con el conjunto Train+Validation y evaluar en Test:

| MÃ©trica | Valor |
|--------|--------|
| **AUC-ROC** | **0.903** |
| Accuracy | 0.8578 |
| Recall (t = 0.5) | 0.609 |
| F1-Score | 0.698 |
| Recall optimizado | **0.70** |

### ğŸ”¥ Mejora tras optimizar threshold

- Churners detectados: **173 â†’ 200**  
- Falsos negativos reducidos: **111 â†’ 84**  
- Solo aumentaron **21** falsos positivos

Esto representa un beneficio directo para estrategias de retenciÃ³n.

---

## ğŸ† 6. Conclusiones

- El modelo final **supera ampliamente la mÃ©trica objetivo** (AUC â‰¥ 0.88).  
- CatBoost demostrÃ³ ser el algoritmo mÃ¡s estable y eficiente para este tipo de datos heterogÃ©neos.  
- El proyecto implementa prÃ¡cticas avanzadas como validaciÃ³n cruzada, pruebas de cordura y tuning inteligente.  
- La optimizaciÃ³n del threshold permite adaptar el modelo a las necesidades del negocio (priorizar recall).  
- El pipeline es sÃ³lido, modular y adecuado para despliegue en producciÃ³n.

---

## ğŸ“Œ 7. TecnologÃ­as Utilizadas

- **Python**
- Pandas, NumPy  
- Scikit-Learn  
- CatBoost  
- LightGBM  
- Matplotlib, Seaborn  
- Jupyter Notebook  

---

## ğŸ‘¨â€ğŸ’» 8. Autor

**Javier AndrÃ©s DÃ­az Charry**  
Data Science & Machine Learning  
ğŸ“ Huesca, EspaÃ±a  
ğŸ”— LinkedIn: *[www.linkedin.com/in/javier-andres-diaz-data-scientist]*

---

## â­ Notebook Completo

El notebook con todo el anÃ¡lisis y visualizaciones se encuentra en el archivo principal del repositorio.

